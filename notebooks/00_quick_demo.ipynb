{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üê±üê∂ Oxford-IIIT Pet Classification - Quick Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/oxford-pets-classification/blob/main/notebooks/00_quick_demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the complete pipeline for binary pet classification (Cat vs Dog) using custom CNN architectures.\n",
    "\n",
    "**What you'll see:**\n",
    "- üöÄ Automatic setup and installation\n",
    "- üìä Training a CNN from scratch\n",
    "- üìà Visualizing results with interactive plots\n",
    "- üîç Model interpretation with Grad-CAM\n",
    "\n",
    "**Estimated time:** 10-15 minutes (with Colab GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ‚öôÔ∏è Setup\n",
    "\n",
    "First, let's clone the repository and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone repository (replace YOUR_USERNAME with your GitHub username)\n",
    "!git clone https://github.com/YOUR_USERNAME/oxford-pets-classification.git\n",
    "%cd oxford-pets-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU available. Training will be slower.\")\n",
    "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## üì¶ Imports\n",
    "\n",
    "Import our custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_modules"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from configs.config import BinaryClassificationConfig\n",
    "from models.architectures import get_model, count_parameters\n",
    "from utils.data_utils import prepare_binary_dataloaders\n",
    "from utils.trainer import BinaryTrainer\n",
    "from utils.visualization import plot_training_curves\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## üéõÔ∏è Configuration\n",
    "\n",
    "Set up training parameters. We'll use model **v3** (best performance) with reduced epochs for demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_config"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = BinaryClassificationConfig\n",
    "config.MODEL_VERSION = 'v3'  # Best model\n",
    "config.EPOCHS = 5  # Quick demo (use 20 for full training)\n",
    "config.BATCH_SIZE = 64  # Larger batch for GPU\n",
    "config.DEVICE = device\n",
    "config.create_directories()\n",
    "\n",
    "print(\"üìã Configuration:\")\n",
    "print(f\"   Model: v3 (VGG-like with augmentation)\")\n",
    "print(f\"   Epochs: {config.EPOCHS}\")\n",
    "print(f\"   Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"   Learning Rate: {config.LEARNING_RATE}\")\n",
    "print(f\"   Device: {config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": [
    "## üìä Load Dataset\n",
    "\n",
    "The Oxford-IIIT Pet dataset will be downloaded automatically (~800MB, one-time download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "print(\"üì• Loading dataset...\")\n",
    "print(\"   This may take a few minutes on first run.\")\n",
    "\n",
    "train_loader, val_loader, test_loader, id_to_binary = prepare_binary_dataloaders(\n",
    "    config, \n",
    "    use_augmentation=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset loaded!\")\n",
    "print(f\"   Train samples: {len(train_loader.dataset):,}\")\n",
    "print(f\"   Validation samples: {len(val_loader.dataset):,}\")\n",
    "print(f\"   Test samples: {len(test_loader.dataset):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize_data"
   },
   "source": [
    "### üñºÔ∏è Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_samples"
   },
   "outputs": [],
   "source": [
    "# Get a batch of images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Denormalize for visualization\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(8):\n",
    "    img = images[i].numpy().transpose(1, 2, 0)\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    label = \"Dog\" if labels[i].item() == 1 else \"Cat\"\n",
    "    color = 'orange' if label == \"Dog\" else 'blue'\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(label, color=color, fontweight='bold', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images with Data Augmentation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model"
   },
   "source": [
    "## üß† Create Model\n",
    "\n",
    "Model v3 is a VGG-like architecture with:\n",
    "- 5 convolutional blocks\n",
    "- Batch normalization\n",
    "- Dropout regularization\n",
    "- ~15M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = get_model('binary_v3')\n",
    "model = model.to(config.DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "print(\"üß† Model Architecture: BinaryCNN_v3\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Model size: ~{total_params * 4 / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## üöÄ Training\n",
    "\n",
    "Let's train the model! This will take approximately:\n",
    "- **With GPU:** ~2-3 minutes per epoch\n",
    "- **Without GPU:** ~10-15 minutes per epoch\n",
    "\n",
    "You'll see:\n",
    "- Progress bar for each epoch\n",
    "- Train and validation metrics\n",
    "- Best model is saved automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_training"
   },
   "outputs": [],
   "source": [
    "# Setup training\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.LEARNING_RATE,\n",
    "    weight_decay=config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "save_dir = config.CHECKPOINT_DIR / config.EXPERIMENT_NAME\n",
    "trainer = BinaryTrainer(\n",
    "    model=model,\n",
    "    device=config.DEVICE,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training setup complete!\")\n",
    "print(f\"   Checkpoints will be saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# Train!\n",
    "print(\"üöÄ Starting training...\\n\")\n",
    "\n",
    "history = trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=config.EPOCHS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## üìà Training Results\n",
    "\n",
    "Let's visualize the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_curves"
   },
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plot_training_curves(\n",
    "    history,\n",
    "    title=\"Binary Classification - Model v3\"\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nüìä Training Summary:\")\n",
    "print(f\"   Best Validation Accuracy: {trainer.best_val_acc:.4f} ({trainer.best_val_acc*100:.2f}%)\")\n",
    "print(f\"   Best Epoch: {trainer.best_epoch}/{config.EPOCHS}\")\n",
    "print(f\"   Final Train Accuracy: {history['train_acc'][-1]:.4f}\")\n",
    "print(f\"   Final Val Accuracy: {history['val_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## üß™ Test Set Evaluation\n",
    "\n",
    "Now let's see how well the model performs on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_eval"
   },
   "outputs": [],
   "source": [
    "print(\"üß™ Evaluating on test set...\\n\")\n",
    "\n",
    "test_loss, test_acc = trainer.evaluate(test_loader)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compare with validation\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"   Best Validation Acc: {trainer.best_val_acc*100:.2f}%\")\n",
    "print(f\"   Test Acc: {test_acc*100:.2f}%\")\n",
    "gap = abs(trainer.best_val_acc - test_acc) * 100\n",
    "print(f\"   Gap: {gap:.2f}%\")\n",
    "\n",
    "if gap < 2:\n",
    "    print(\"   ‚úÖ Good generalization!\")\n",
    "elif gap < 5:\n",
    "    print(\"   ‚ö†Ô∏è Some overfitting detected\")\n",
    "else:\n",
    "    print(\"   ‚ùå Significant overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predictions"
   },
   "source": [
    "## üîÆ Sample Predictions\n",
    "\n",
    "Let's visualize some predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_predictions"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get random test samples\n",
    "model.eval()\n",
    "indices = random.sample(range(len(test_loader.dataset)), 12)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, test_idx in enumerate(indices):\n",
    "        img_tensor, true_label = test_loader.dataset[test_idx]\n",
    "        \n",
    "        # Predict\n",
    "        img_input = img_tensor.unsqueeze(0).to(config.DEVICE)\n",
    "        output = model(img_input)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        pred_label = 1 if prob > 0.5 else 0\n",
    "        \n",
    "        # Denormalize\n",
    "        img = img_tensor.cpu().numpy().transpose(1, 2, 0)\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Plot\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        true_class = \"Dog\" if true_label == 1 else \"Cat\"\n",
    "        pred_class = \"Dog\" if pred_label == 1 else \"Cat\"\n",
    "        confidence = prob if pred_label == 1 else (1 - prob)\n",
    "        \n",
    "        title = f\"True: {true_class}\\nPred: {pred_class} ({confidence*100:.1f}%)\"\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        axes[idx].set_title(title, color=color, fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Sample Predictions on Test Set', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate accuracy for these samples\n",
    "correct = sum(1 for i in range(len(indices)) \n",
    "              if test_loader.dataset[indices[i]][1] == \n",
    "              (1 if torch.sigmoid(model(test_loader.dataset[indices[i]][0].unsqueeze(0).to(config.DEVICE))).item() > 0.5 else 0))\n",
    "print(f\"\\n‚úÖ Accuracy on displayed samples: {correct}/{len(indices)} ({correct/len(indices)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "Great job! You've successfully trained a CNN for binary classification.\n",
    "\n",
    "**Try these next:**\n",
    "\n",
    "1. **Train longer:** Change `config.EPOCHS = 20` for better accuracy\n",
    "2. **Compare models:** Try v0, v1, v2 to see the improvement\n",
    "3. **Multi-class classification:** Check out `01_multiclass_classification.ipynb`\n",
    "4. **Transfer learning:** See `02_transfer_learning.ipynb` for ResNet50\n",
    "\n",
    "**Expected accuracies:**\n",
    "- Model v0 (simple): ~85%\n",
    "- Model v1: ~88%\n",
    "- Model v2: ~91%\n",
    "- Model v3 (this one, 20 epochs): **~94%**\n",
    "- ResNet50 transfer learning: **~89%** (multi-class)\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Resources\n",
    "\n",
    "- [GitHub Repository](https://github.com/YOUR_USERNAME/oxford-pets-classification)\n",
    "- [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)\n",
    "- [PyTorch Documentation](https://pytorch.org/docs/)\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for deep learning education**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
